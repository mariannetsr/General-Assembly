{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Thoughts on Model Workflow - June '20\n",
    "\n",
    "We will make the following distinctions:\n",
    "\n",
    "- Model Selection will refer to choosing the best hyper parameters for a given learning method.\n",
    "\n",
    "- Algorithm Selection will refer to choosing the best learning method (e.g LogReg, RF, SVM etc).\n",
    "\n",
    "\n",
    "- Hyperparameters are the parameters of the learning method itself which must be set a priori, i.e. before the model is fit.\n",
    "\n",
    "- Model parameters correspond to the parameters learned by the model upon training.\n",
    "\n",
    "### Best practice given enough data\n",
    "\n",
    "#### Model Selection - fixed learning method\n",
    "\n",
    "1. Split the data into train, test, and validation.\n",
    "2. Train as many models as there are hyperparameter combinations on the train set.\n",
    "3. Evaluate each of these models on the validation set.\n",
    "4. Select the model with the best performance on the validation set. \n",
    "5. Retrain the model on the combined train + validation sets using 'winning' hyperparameter combination.\n",
    "6. Estimate generalisation performance on the test set. If the test error is similar to the validation error then we have belief that this model will generalise well to unseen data.\n",
    "7. Finally retrain the model with the choosen hyperparameters on the entire set before production. \n",
    "\n",
    "#### Algorithm Selection\n",
    "\n",
    "- We can follow the above reasoning but split the data into independent train, validation, test sets for each learning method we are testing. \n",
    "- This obviously only works if we have a large amount of data at our disposal. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If data is limited but model is fixed\n",
    "\n",
    "1. Split the data into train, test.\n",
    "2. Use crossvalidation on the train set to find optimal hyperparameters.\n",
    "3. Train the model with the best hyperparameter combination on the entire training set.\n",
    "4. Estimate generalisation performance on the test set. If the test error is similar to the validation error then we have belief that this model will generalise well to unseen data.\n",
    "5. Finally retrain the model with the choosen hyperparameters on the entire set before production. \n",
    "\n",
    "#### Algorithm Selection\n",
    "\n",
    "- If we want our final model to generalise well we should use different sets to a) choose between learning algorithms, and b) tune the corresponding hyperparameters. \n",
    "- We employ nested crossvalidation to achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code and comments have been taken from: https://github.com/esentri/datascience_blog_resources/blob/master/model_selection.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit: David Schönleber\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Wisconsin breast cancer dataset for illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_df = pd.read_csv('./data/combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_df.drop(['incident_id', 'date', 'city_or_county', 'n_casualties', 'n_killed', 'n_injured', 'democrat', 'republican'],\n",
    "            axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congressional_district</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state_house_district</th>\n",
       "      <th>state_senate_district</th>\n",
       "      <th>day</th>\n",
       "      <th>agegroup_child</th>\n",
       "      <th>agegroup_teen</th>\n",
       "      <th>agegroup_adult</th>\n",
       "      <th>num_males</th>\n",
       "      <th>...</th>\n",
       "      <th>state_Texas</th>\n",
       "      <th>state_Utah</th>\n",
       "      <th>state_Vermont</th>\n",
       "      <th>state_Virginia</th>\n",
       "      <th>state_Washington</th>\n",
       "      <th>state_West Virginia</th>\n",
       "      <th>state_Wisconsin</th>\n",
       "      <th>state_Wyoming</th>\n",
       "      <th>political_democrat</th>\n",
       "      <th>political_republican</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43.2301</td>\n",
       "      <td>-86.2514</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>40.7417</td>\n",
       "      <td>-74.1695</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>40.7034</td>\n",
       "      <td>-73.7474</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>40.6715</td>\n",
       "      <td>-73.9476</td>\n",
       "      <td>43.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>37.2646</td>\n",
       "      <td>-93.3007</td>\n",
       "      <td>131.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   congressional_district  latitude  longitude  state_house_district  \\\n",
       "0                     2.0   43.2301   -86.2514                  92.0   \n",
       "1                    10.0   40.7417   -74.1695                  29.0   \n",
       "2                     5.0   40.7034   -73.7474                  33.0   \n",
       "3                     9.0   40.6715   -73.9476                  43.0   \n",
       "4                     7.0   37.2646   -93.3007                 131.0   \n",
       "\n",
       "   state_senate_district  day  agegroup_child  agegroup_teen  agegroup_adult  \\\n",
       "0                   34.0    1               0              0               1   \n",
       "1                   29.0    1               0              0               0   \n",
       "2                   14.0    1               0              0               2   \n",
       "3                   20.0    1               0              0               2   \n",
       "4                   30.0    1               1              1               0   \n",
       "\n",
       "   num_males  ...  state_Texas  state_Utah  state_Vermont  state_Virginia  \\\n",
       "0          0  ...            0           0              0               0   \n",
       "1          0  ...            0           0              0               0   \n",
       "2          2  ...            0           0              0               0   \n",
       "3          2  ...            0           0              0               0   \n",
       "4          0  ...            0           0              0               0   \n",
       "\n",
       "   state_Washington  state_West Virginia  state_Wisconsin  state_Wyoming  \\\n",
       "0                 0                    0                0              0   \n",
       "1                 0                    0                0              0   \n",
       "2                 0                    0                0              0   \n",
       "3                 0                    0                0              0   \n",
       "4                 0                    0                0              0   \n",
       "\n",
       "   political_democrat  political_republican  \n",
       "0                   1                     0  \n",
       "1                   1                     0  \n",
       "2                   1                     0  \n",
       "3                   1                     0  \n",
       "4                   0                     1  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gun_df = pd.concat([gun_df,pd.get_dummies(gun_df[['month','year','day_of_week','state','political']], drop_first = False)], axis = 1)\n",
    "gun_df.drop(['month','year','day_of_week','state','political'], axis=1, inplace=True)\n",
    "gun_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189240, 89)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gun_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested CV (5x2-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test set (to assess generalization error)\n",
    "X = gun_df.drop(['casualties'], axis=1)\n",
    "y = gun_df['casualties']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initializing Classifiers\n",
    "clf_lr  = LogisticRegression(solver='lbfgs', random_state=0, max_iter=1000)\n",
    "clf_rf  = RandomForestClassifier(random_state=0)\n",
    "clf_svc = SVC(random_state=0)\n",
    "clf_knn = KNeighborsClassifier()\n",
    "\n",
    "# Building the model pipelines incl. preprocessing where needed \n",
    "# Note that the random forest does not need feature scaling\n",
    "pipe_lr  = Pipeline([('std', StandardScaler()),\n",
    "                     ('clf_lr', clf_lr)])\n",
    "\n",
    "pipe_svc = Pipeline([('std', StandardScaler()),\n",
    "                     ('clf_svc', clf_svc)])\n",
    "\n",
    "pipe_knn = Pipeline([('std', StandardScaler()),\n",
    "                     ('clf_knn', clf_knn)])\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid_lr  = [{'clf_lr__penalty': ['l2'],\n",
    "                   'clf_lr__C': np.logspace(-4, 4, 9)}]\n",
    "\n",
    "param_grid_knn = [{'clf_knn__n_neighbors': list(range(1, 10)),\n",
    "                   'clf_knn__p': [1, 2],\n",
    "                   'clf_knn__leaf_size': np.arange(10,51,10)}]\n",
    "\n",
    "param_grid_rf  = [{'n_estimators': [10, 50, 100, 250, 500, 1000],\n",
    "                   'min_samples_leaf': [1, 3, 5],\n",
    "                   'max_features': ['sqrt', 'log2']}]\n",
    "\n",
    "param_grid_svc = [{'clf_svc__kernel': ['rbf'],\n",
    "                   'clf_svc__C': np.logspace(-4, 4, 9),\n",
    "                    'clf_svc__gamma': np.logspace(-4, 0, 4)},\n",
    "                  {'clf_svc__kernel': ['linear'],\n",
    "                   'clf_svc__C': np.logspace(-4, 4, 9)}]\n",
    "\n",
    "# Setting up multiple GridSearchCV objects, one for each algorithm\n",
    "gridcvs = {}\n",
    "inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=4)\n",
    "\n",
    "for pgrid, est, name in zip((param_grid_lr, param_grid_knn,\n",
    "                             param_grid_rf, param_grid_svc),\n",
    "                            (pipe_lr, pipe_knn, clf_rf, pipe_svc),\n",
    "                            ('LogisticRegression', 'KNN', 'RF', 'SVM')):\n",
    "    gcv = GridSearchCV(estimator=est,\n",
    "                       param_grid=pgrid,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=1,\n",
    "                       cv=inner_cv,\n",
    "                       verbose=0,\n",
    "                       refit=True)\n",
    "    gridcvs[name] = gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)\n",
    "outer_scores = {}\n",
    "\n",
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    nested_score = cross_val_score(gs_est, \n",
    "                                   X=X_train, \n",
    "                                   y=y_train, \n",
    "                                   cv=outer_cv,\n",
    "                                   n_jobs=1)\n",
    "    outer_scores[name] = nested_score\n",
    "    print(nested_score)\n",
    "    print(f'{name}: outer accuracy {100*nested_score.mean():.2f} +/- {100*nested_score.std():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we do not care about hyperparameter values, but about which learning algorithm (Random Forest, Logistic Regression etc.) yields stable results irrespective of their particular choice of hyperparameters. The outer-fold cross-validation is not concerned with hyperparameter selection (this is what is done inside the inner fold), but with estimating the generalization error of the learning algorithms. (In this sense, hyperparameter tuning can be thought of as part of the model fitting process [2], which is being done within the inner fold.)\n",
    "\n",
    "The goal at this stage is to find a learning algorithm which performs well irrespective of the particular subset of the training set chosen for the model training (and hence specific hyperparameter values). This assumes that the 5 (number of outer fold splits) potentially different models are comparable to the final model trained on the full training data, or at least comparable to each other. Since the number of training samples in the cross-validation procedure is smaller than in the full training set, we might get a pessimistically biased estimate of the model performance, depending on how the performance of the learning algorithm varies with the size of the training set [3].\n",
    "\n",
    "If the hyperparameter optimization process is unstable, i.e., if the models determined in the inner cross-validation fold are not comparable to each other (e.g. since they are overfitting the data or since the data is noisy), we expect the learning algorithm to exhibit high variance in the outer cross-validation loop. Hence, in order to be confident that our selected learning algorithm will have a similar performance on yet unseen data when fitted on the full training data, we select the learning algorithm with high mean accuracy and low variance on the outer cross-validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit \"best\" algorithm on the full training set\n",
    "algo_best = 'LogisticRegression'\n",
    "algo = gridcvs[algo_best]\n",
    "algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=algo.predict(X_test))\n",
    "\n",
    "# evaluate performance and compare to cross-validation results\n",
    "print(f'Accuracy (mean cross-vaidated score of the best_estimator): {100*algo.best_score_:.2f}')\n",
    "print(f'Best Parameters: {gridcvs[algo_best].best_params_}')\n",
    "\n",
    "print(f'Training Accuracy: {100*train_acc:.2f}')\n",
    "print(f'Test Accuracy: {100*test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the mean cross-validated accuracy on the training set is lower than the test accuracy, indicating that the cross-validation score is a pessimistic estimate (i.e., more training data makes the model better).\n",
    "\n",
    "The final step (which we omit here) is to train the final algorithm with the final set of hyperparameters on the full available data before deploying it in the real world. After fitting with the full available data we do no longer have an estimate of the generalization error of the resulting model. However, since we have thoroughly estimated the generalization error beforehand, we have reason to believe that the model will not perform worse on unseen data (sampled from the same distribution as training and test data) than the model whose generalization error we estimated above with the help of the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves for estimating the variation of the learning algorithm performance with training set size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, to estimate how the model performance varies with training set size, we plot learning curves for our classifiers (standard parameters). This also illustrates why we might get a pessimistic estimate when doing cross-validation: the training data might just be too small for our learning algorithm to get to its best possible performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_learning_curve(estimator, clf, X, y, ylim=None, cv=None, train_sizes=None):\n",
    "    plt.figure()\n",
    "    plt.title(f'Learning Curves ({clf})')\n",
    "    plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    return\n",
    "\n",
    "train_sizes = np.linspace(.1, 1.0, 5)\n",
    "ylim = (0.9, 1.01)\n",
    "cv = 5\n",
    "plot_learning_curve(pipe_lr, \"Logistic Regression\", X_train, y_train, \n",
    "                    ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "plot_learning_curve(clf_rf, \"Random Forest\", X_train, y_train, \n",
    "                    ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "plot_learning_curve(pipe_knn, \"KNN\", X_train, y_train, \n",
    "                    ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "plot_learning_curve(pipe_svc, \"SVC\", X_train, y_train, \n",
    "                    ylim=ylim, cv=cv, train_sizes=train_sizes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the training score in the learning curve for Logistic Regression (KNN, SVC) increases with larger sample size rather than decreasing with increasing training size. This indicates that the size of the training set is not sufficient to fit the model parameters well (not surprisingly, given that we have 30 features - from the \"one in ten\" rule of thumb we would expect to need > 300 data points to fit our Logistic Regression model well).\n",
    "\n",
    "Besides, the standard deviation of the cross-validation score ($\\approx 1$) for Logistic Regression is comparable with the standard deviation obtained in the outer fold of the nested cross-validation routine above, indicating that the hyperparameter optimization in the inner loop is stable, i.e., the resulting scores vary not more than is expected. In contast, the Random Forest is severely overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] *Model evaluation, model selection, and algorithm selection in machine learning* by Sebastian Raschka, [PDF](https://sebastianraschka.com/pdf/manuscripts/model-eval.pdf).\n",
    "\n",
    "[2] Stackexchange discussions [here](https://stats.stackexchange.com/questions/65128/nested-cross-validation-for-model-selection), [here](https://stats.stackexchange.com/questions/251752/model-selection-problem-using-nested-cross-validation-in-presence-of-several-alt), and [here](https://stats.stackexchange.com/questions/232897/how-to-build-the-final-model-and-tune-probability-threshold-after-nested-cross-v)\n",
    "\n",
    "[3] Hastie T., Tibshirani R., and Friedman J., *The Elements of Statistical Learning*, New York, NY, USA: Springer New York Inc. (2008). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
